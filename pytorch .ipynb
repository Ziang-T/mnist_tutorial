{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:21<00:00, 21.62it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.38it/s]\n",
      "  1%|          | 3/468 [00:00<00:17, 26.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] Train Loss: 0.78197 Train Accuracy: 0.82068\n",
      "[Epoch: 1] Test Loss: 0.27383 Test Accuracy: 0.93610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:17<00:00, 27.49it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 40.80it/s]\n",
      "  1%|          | 3/468 [00:00<00:16, 28.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2] Train Loss: 0.20731 Train Accuracy: 0.93718\n",
      "[Epoch: 2] Test Loss: 0.14653 Test Accuracy: 0.95743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 29.02it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 53.09it/s]\n",
      "  1%|          | 4/468 [00:00<00:15, 29.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 3] Train Loss: 0.13008 Train Accuracy: 0.96120\n",
      "[Epoch: 3] Test Loss: 0.11232 Test Accuracy: 0.96575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:17<00:00, 27.03it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 47.32it/s]\n",
      "  1%|          | 3/468 [00:00<00:16, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 4] Train Loss: 0.09777 Train Accuracy: 0.97067\n",
      "[Epoch: 4] Test Loss: 0.09278 Test Accuracy: 0.97115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 28.12it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.68it/s]\n",
      "  1%|          | 3/468 [00:00<00:16, 28.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 5] Train Loss: 0.07735 Train Accuracy: 0.97574\n",
      "[Epoch: 5] Test Loss: 0.08630 Test Accuracy: 0.97306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 27.54it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.69it/s]\n",
      "  1%|          | 3/468 [00:00<00:16, 27.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 6] Train Loss: 0.06416 Train Accuracy: 0.98002\n",
      "[Epoch: 6] Test Loss: 0.08068 Test Accuracy: 0.97546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 28.79it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.60it/s]\n",
      "  1%|          | 3/468 [00:00<00:17, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 7] Train Loss: 0.05403 Train Accuracy: 0.98302\n",
      "[Epoch: 7] Test Loss: 0.07159 Test Accuracy: 0.97766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 28.35it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.82it/s]\n",
      "  1%|          | 3/468 [00:00<00:17, 26.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 8] Train Loss: 0.04605 Train Accuracy: 0.98506\n",
      "[Epoch: 8] Test Loss: 0.06398 Test Accuracy: 0.98057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 28.40it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.85it/s]\n",
      "  1%|          | 3/468 [00:00<00:16, 28.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 9] Train Loss: 0.03979 Train Accuracy: 0.98723\n",
      "[Epoch: 9] Test Loss: 0.07154 Test Accuracy: 0.97766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:16<00:00, 28.38it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 10] Train Loss: 0.03542 Train Accuracy: 0.98831\n",
      "[Epoch: 10] Test Loss: 0.07456 Test Accuracy: 0.97867\n",
      "Training Accuracy: 98.83%\n",
      "Testing Accuracy: 97.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    # TODO:define model\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 576)\n",
    "        self.bc1 = nn.BatchNorm1d(576)\n",
    "\n",
    "        self.fc2 = nn.Linear(576, 324)\n",
    "        self.bc2 = nn.BatchNorm1d(324)\n",
    "\n",
    "        self.fc3 = nn.Linear(324, 144)\n",
    "        self.bc3 = nn.BatchNorm1d(144)\n",
    "\n",
    "        self.fc4 = nn.Linear(144, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 784))\n",
    "        h = self.fc1(x)\n",
    "        h = self.bc1(h)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = nn.functional.dropout(h, p=0.5, training=self.training)  \n",
    "\n",
    "        h = self.fc2(h)\n",
    "        h = self.bc2(h)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = nn.functional.dropout(h, p=0.2, training=self.training)  \n",
    "\n",
    "        h = self.fc3(h)\n",
    "        h = self.bc3(h)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = nn.functional.dropout(h, p=0.1, training=self.training)  \n",
    "\n",
    "        h = self.fc4(h)\n",
    "        out = nn.functional.log_softmax(h, dim=0)\n",
    "        return out\n",
    "\n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # TODO:forward + backward + optimize\n",
    "        optimizer.zero_grad()  \n",
    "        out = model(images)  \n",
    "        lossvalue = criterion(out, labels) \n",
    "        optimizer.zero_grad()  \n",
    "        lossvalue.backward()  \n",
    "        optimizer.step() \n",
    "        train_loss += float(lossvalue)\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == labels).sum()\n",
    "        acc = int(num_correct) / images.shape[0]\n",
    "        train_acc += acc\n",
    "        \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    model.eval()  \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.view(-1, 784)\n",
    "        testout = model(images)\n",
    "        testloss = criterion(testout, labels)\n",
    "        eval_loss += float(testloss)\n",
    "\n",
    "        _, pred = testout.max(1)\n",
    "        num_correct = (pred == labels).sum()\n",
    "        acc = int(num_correct) / images.shape[0]\n",
    "        eval_acc += acc\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = train_acc / len(train_loader)\n",
    "    eval_loss = eval_loss / len(test_loader)\n",
    "    eval_acc = eval_acc / len(test_loader)\n",
    "    print(\"[Epoch: %d] Train Loss: %5.5f Train Accuracy: %5.5f\" % (epoch + 1, train_loss, train_acc))\n",
    "    print(\"[Epoch: %d] Test Loss: %5.5f Test Accuracy: %5.5f\" % (epoch + 1, eval_loss, eval_acc))\n",
    "\n",
    "print('Training Accuracy: %.2f%%' % (train_acc * 100))\n",
    "print('Testing Accuracy: %.2f%%' % (eval_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
